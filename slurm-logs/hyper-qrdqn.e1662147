
Currently Loaded Modules:
  1) intel/19.1.1   3) autotools/1.4   5) cmake/3.24.2   7) xalt/2.10.32
  2) impi/19.0.9    4) python3/3.9.7   6) pmix/3.2.3     8) TACC

 

2024-04-27 20:07:50.757383: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)
[Powered by Stella]
/work/09894/nicolas_/ls6/miniconda3/envs/rl-final/lib/python3.10/site-packages/gymnasium/envs/registration.py:877: UserWarning: [33mWARN: `gymnasium.make(..., autoreset=True)` is deprecated and will be removed in v1.0[0m
  logger.warn(
/work/09894/nicolas_/ls6/miniconda3/envs/rl-final/lib/python3.10/site-packages/optuna/samplers/_tpe/sampler.py:319: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.
  warnings.warn(
[I 2024-04-27 20:08:03,640] A new study created in memory with name: no-name-a1cdfb01-158a-41c8-8c5e-aabb2127f0f1
/work/09894/nicolas_/ls6/miniconda3/envs/rl-final/lib/python3.10/site-packages/gymnasium/envs/registration.py:877: UserWarning: [33mWARN: `gymnasium.make(..., autoreset=True)` is deprecated and will be removed in v1.0[0m
  logger.warn(
[I 2024-04-27 20:08:35,810] Trial 0 finished with value: -1.6 and parameters: {'gamma': 0.995, 'learning_rate': 2.2047239675056044e-05, 'batch_size': 64, 'buffer_size': 50000, 'exploration_final_eps': 0.09112884806516973, 'exploration_fraction': 0.28337004451256287, 'target_update_interval': 5000, 'learning_starts': 10000, 'train_freq': 4, 'subsample_steps': 1, 'net_arch': 'small', 'n_quantiles': 34}. Best is trial 0 with value: -1.6.
[I 2024-04-27 20:08:49,413] Trial 6 finished with value: -6.4 and parameters: {'gamma': 0.995, 'learning_rate': 0.0002810607485608676, 'batch_size': 512, 'buffer_size': 10000, 'exploration_final_eps': 0.12020601920143509, 'exploration_fraction': 0.4627662113394493, 'target_update_interval': 1000, 'learning_starts': 20000, 'train_freq': 128, 'subsample_steps': 8, 'net_arch': 'tiny', 'n_quantiles': 119}. Best is trial 0 with value: -1.6.
[I 2024-04-27 20:09:05,427] Trial 7 finished with value: -1.6 and parameters: {'gamma': 0.95, 'learning_rate': 7.399836336612149e-05, 'batch_size': 128, 'buffer_size': 1000000, 'exploration_final_eps': 0.17389280814290417, 'exploration_fraction': 0.31313625663917094, 'target_update_interval': 1, 'learning_starts': 10000, 'train_freq': 8, 'subsample_steps': 4, 'net_arch': 'small', 'n_quantiles': 141}. Best is trial 0 with value: -1.6.
[W 2024-04-27 20:09:05,686] Trial 10 failed with parameters: {'gamma': 0.995, 'learning_rate': 0.002454259601369883, 'batch_size': 64, 'buffer_size': 1000000, 'exploration_final_eps': 0.006302028330982457, 'exploration_fraction': 0.47496858584114005, 'target_update_interval': 1, 'learning_starts': 0, 'train_freq': 4, 'subsample_steps': 2, 'net_arch': 'small', 'n_quantiles': 127} because of the following error: MemoryError((1000000, 1, 4, 84, 84), dtype('uint8')).
Traceback (most recent call last):
  File "/work/09894/nicolas_/ls6/miniconda3/envs/rl-final/lib/python3.10/site-packages/optuna/study/_optimize.py", line 196, in _run_trial
    value_or_values = func(trial)
  File "/work/09894/nicolas_/ls6/miniconda3/envs/rl-final/lib/python3.10/site-packages/rl_zoo3/exp_manager.py", line 753, in objective
    model = ALGOS[self.algo](
  File "/work/09894/nicolas_/ls6/miniconda3/envs/rl-final/lib/python3.10/site-packages/sb3_contrib/qrdqn/qrdqn.py", line 145, in __init__
    self._setup_model()
  File "/work/09894/nicolas_/ls6/miniconda3/envs/rl-final/lib/python3.10/site-packages/sb3_contrib/qrdqn/qrdqn.py", line 148, in _setup_model
    super()._setup_model()
  File "/work/09894/nicolas_/ls6/miniconda3/envs/rl-final/lib/python3.10/site-packages/stable_baselines3/common/off_policy_algorithm.py", line 189, in _setup_model
    self.replay_buffer = self.replay_buffer_class(
  File "/work/09894/nicolas_/ls6/miniconda3/envs/rl-final/lib/python3.10/site-packages/stable_baselines3/common/buffers.py", line 212, in __init__
    self.observations = np.zeros((self.buffer_size, self.n_envs, *self.obs_shape), dtype=observation_space.dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 26.3 GiB for an array with shape (1000000, 1, 4, 84, 84) and data type uint8
[W 2024-04-27 20:09:05,707] Trial 10 failed with value None.
[I 2024-04-27 20:09:07,995] Trial 1 finished with value: -6.4 and parameters: {'gamma': 0.9999, 'learning_rate': 0.00043750846661987043, 'batch_size': 16, 'buffer_size': 1000000, 'exploration_final_eps': 0.04496815158423484, 'exploration_fraction': 0.15078568962843963, 'target_update_interval': 1, 'learning_starts': 20000, 'train_freq': 16, 'subsample_steps': 4, 'net_arch': 'tiny', 'n_quantiles': 36}. Best is trial 0 with value: -1.6.
[I 2024-04-27 20:09:45,753] Trial 5 finished with value: -6.4 and parameters: {'gamma': 0.995, 'learning_rate': 0.024271056434722837, 'batch_size': 100, 'buffer_size': 100000, 'exploration_final_eps': 0.1754597815757066, 'exploration_fraction': 0.0238447076346755, 'target_update_interval': 20000, 'learning_starts': 1000, 'train_freq': 128, 'subsample_steps': 8, 'net_arch': 'medium', 'n_quantiles': 160}. Best is trial 0 with value: -1.6.
[I 2024-04-27 20:09:56,251] Trial 2 finished with value: -6.4 and parameters: {'gamma': 0.98, 'learning_rate': 0.4901157322192294, 'batch_size': 64, 'buffer_size': 50000, 'exploration_final_eps': 0.087746998503185, 'exploration_fraction': 0.21561262263035225, 'target_update_interval': 15000, 'learning_starts': 1000, 'train_freq': 128, 'subsample_steps': 4, 'net_arch': 'tiny', 'n_quantiles': 102}. Best is trial 0 with value: -1.6.
[I 2024-04-27 20:11:36,873] Trial 9 finished with value: -1.6 and parameters: {'gamma': 0.99, 'learning_rate': 0.0596368910596999, 'batch_size': 64, 'buffer_size': 10000, 'exploration_final_eps': 0.19204187398197659, 'exploration_fraction': 0.10941664107721416, 'target_update_interval': 1000, 'learning_starts': 1000, 'train_freq': 1000, 'subsample_steps': 2, 'net_arch': 'tiny', 'n_quantiles': 147}. Best is trial 0 with value: -1.6.
[I 2024-04-27 20:12:39,273] Trial 8 finished with value: -6.4 and parameters: {'gamma': 0.95, 'learning_rate': 0.004070525406217954, 'batch_size': 512, 'buffer_size': 1000000, 'exploration_final_eps': 0.12161201783283271, 'exploration_fraction': 0.4254175383529569, 'target_update_interval': 5000, 'learning_starts': 1000, 'train_freq': 1000, 'subsample_steps': 8, 'net_arch': 'small', 'n_quantiles': 22}. Best is trial 0 with value: -1.6.
[I 2024-04-27 20:13:20,457] Trial 4 finished with value: -3.2 and parameters: {'gamma': 0.98, 'learning_rate': 0.010143037735999678, 'batch_size': 64, 'buffer_size': 10000, 'exploration_final_eps': 0.0610400156221675, 'exploration_fraction': 0.27819352204201303, 'target_update_interval': 1, 'learning_starts': 1000, 'train_freq': 1000, 'subsample_steps': 1, 'net_arch': 'medium', 'n_quantiles': 15}. Best is trial 0 with value: -1.6.
[I 2024-04-27 20:57:48,226] Trial 3 finished with value: -1.6 and parameters: {'gamma': 0.999, 'learning_rate': 0.19632222530775628, 'batch_size': 512, 'buffer_size': 1000000, 'exploration_final_eps': 0.01716498447225483, 'exploration_fraction': 0.11403636607190742, 'target_update_interval': 20000, 'learning_starts': 0, 'train_freq': 128, 'subsample_steps': 1, 'net_arch': 'medium', 'n_quantiles': 156}. Best is trial 0 with value: -1.6.
Traceback (most recent call last):
  File "/work/09894/nicolas_/ls6/miniconda3/envs/rl-final/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/work/09894/nicolas_/ls6/miniconda3/envs/rl-final/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/work/09894/nicolas_/ls6/miniconda3/envs/rl-final/lib/python3.10/site-packages/rl_zoo3/train.py", line 279, in <module>
    train()
  File "/work/09894/nicolas_/ls6/miniconda3/envs/rl-final/lib/python3.10/site-packages/rl_zoo3/train.py", line 275, in train
    exp_manager.hyperparameters_optimization()
  File "/work/09894/nicolas_/ls6/miniconda3/envs/rl-final/lib/python3.10/site-packages/rl_zoo3/exp_manager.py", line 873, in hyperparameters_optimization
    study.optimize(self.objective, n_jobs=self.n_jobs, n_trials=self.n_trials)
  File "/work/09894/nicolas_/ls6/miniconda3/envs/rl-final/lib/python3.10/site-packages/optuna/study/study.py", line 451, in optimize
    _optimize(
  File "/work/09894/nicolas_/ls6/miniconda3/envs/rl-final/lib/python3.10/site-packages/optuna/study/_optimize.py", line 99, in _optimize
    f.result()
  File "/work/09894/nicolas_/ls6/miniconda3/envs/rl-final/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/work/09894/nicolas_/ls6/miniconda3/envs/rl-final/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/work/09894/nicolas_/ls6/miniconda3/envs/rl-final/lib/python3.10/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/work/09894/nicolas_/ls6/miniconda3/envs/rl-final/lib/python3.10/site-packages/optuna/study/_optimize.py", line 159, in _optimize_sequential
    frozen_trial = _run_trial(study, func, catch)
  File "/work/09894/nicolas_/ls6/miniconda3/envs/rl-final/lib/python3.10/site-packages/optuna/study/_optimize.py", line 247, in _run_trial
    raise func_err
  File "/work/09894/nicolas_/ls6/miniconda3/envs/rl-final/lib/python3.10/site-packages/optuna/study/_optimize.py", line 196, in _run_trial
    value_or_values = func(trial)
  File "/work/09894/nicolas_/ls6/miniconda3/envs/rl-final/lib/python3.10/site-packages/rl_zoo3/exp_manager.py", line 753, in objective
    model = ALGOS[self.algo](
  File "/work/09894/nicolas_/ls6/miniconda3/envs/rl-final/lib/python3.10/site-packages/sb3_contrib/qrdqn/qrdqn.py", line 145, in __init__
    self._setup_model()
  File "/work/09894/nicolas_/ls6/miniconda3/envs/rl-final/lib/python3.10/site-packages/sb3_contrib/qrdqn/qrdqn.py", line 148, in _setup_model
    super()._setup_model()
  File "/work/09894/nicolas_/ls6/miniconda3/envs/rl-final/lib/python3.10/site-packages/stable_baselines3/common/off_policy_algorithm.py", line 189, in _setup_model
    self.replay_buffer = self.replay_buffer_class(
  File "/work/09894/nicolas_/ls6/miniconda3/envs/rl-final/lib/python3.10/site-packages/stable_baselines3/common/buffers.py", line 212, in __init__
    self.observations = np.zeros((self.buffer_size, self.n_envs, *self.obs_shape), dtype=observation_space.dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 26.3 GiB for an array with shape (1000000, 1, 4, 84, 84) and data type uint8
